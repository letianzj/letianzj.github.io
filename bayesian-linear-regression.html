<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="bokhEjod5-cme1ZueY6aAPHORfnXv9hSoljSfg2Vp_Q">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"letianzj.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Introduction In last post we reviewed the classical linear regression and now let&#39;s look from Bayesian perspective. There is well-known philosophical difference between frequentist and Bayesian. Inte">
<meta property="og:type" content="article">
<meta property="og:title" content="Bayesian Linear Regression">
<meta property="og:url" content="https://letianzj.github.io/bayesian-linear-regression.html">
<meta property="og:site_name" content="Quantitative Investing">
<meta property="og:description" content="Introduction In last post we reviewed the classical linear regression and now let&#39;s look from Bayesian perspective. There is well-known philosophical difference between frequentist and Bayesian. Inte">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://letianzj.github.io/bayesian-linear-regression/bayesian_dynamics.png">
<meta property="og:image" content="https://letianzj.github.io/bayesian-linear-regression/bayesian_dynamics.png">
<meta property="article:published_time" content="2017-12-27T03:35:00.000Z">
<meta property="article:modified_time" content="2020-08-03T20:34:26.158Z">
<meta property="article:author" content="Letian Wang">
<meta property="article:tag" content="Bayesian Inference">
<meta property="article:tag" content="Linear Regression">
<meta property="article:tag" content="Conjugate Prior">
<meta property="article:tag" content="Machine Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://letianzj.github.io/bayesian-linear-regression/bayesian_dynamics.png">

<link rel="canonical" href="https://letianzj.github.io/bayesian-linear-regression.html">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Bayesian Linear Regression | Quantitative Investing</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-109341958-2"></script>
    <script>
      if (CONFIG.hostname === location.hostname) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-109341958-2');
      }
    </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Quantitative Investing</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Letian Wang Blog on Quant Trading and Portfolio Management</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://letianzj.github.io/bayesian-linear-regression.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Letian Wang">
      <meta itemprop="description" content="Letian Wang blog to discuss quantitative trading strategies, portfolio management, risk premia, risk management, systematic trading, and machine learning, deep learning applications in Finance.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Quantitative Investing">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Bayesian Linear Regression
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2017-12-26 22:35:00" itemprop="dateCreated datePublished" datetime="2017-12-26T22:35:00-05:00">2017-12-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-08-03 16:34:26" itemprop="dateModified" datetime="2020-08-03T16:34:26-04:00">2020-08-03</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/bayesian-linear-regression.html#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="bayesian-linear-regression.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="introduction">Introduction</h2>
<p>In <a href="/classical-linear-regression.html" title="last post">last post</a> we reviewed the classical linear regression and now let's look from Bayesian perspective. There is well-known philosophical difference between <a href="https://en.wikipedia.org/wiki/Frequentist_inference" target="_blank" rel="noopener">frequentist</a> and <a href="https://en.wikipedia.org/wiki/Bayesian_inference" target="_blank" rel="noopener">Bayesian</a>. Interested readers can read further this debate online such as <a href="https://en.wikipedia.org/wiki/Probability_interpretations" target="_blank" rel="noopener">this one on Wiki</a>. In my opinion, one advantage of Bayesian is its ability to perform <a href="https://en.wikipedia.org/wiki/Recursive_Bayesian_estimation" target="_blank" rel="noopener">online machine learning</a> recursivelly as new information comes in incrementally.</p>
<p>In terms of the linear regression, <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem" target="_blank" rel="noopener">Bayes's Theorem</a> can be written as</p>
<p><span class="math display">\[
f(\beta|y,X)=\frac{f(y|\beta,X)f(\beta|X)}{f(y|X)}
\tag{1.1}
\]</span></p>
<p>where <span class="math inline">\(f(\beta|X)\)</span> is the <strong>prior</strong> belief of parameter <span class="math inline">\(\beta\)</span>; <span class="math inline">\(f(y|\beta,X)\)</span> is the <strong>likelihood</strong> of observing <span class="math inline">\(y\)</span> given our <strong>prior</strong>; and <span class="math inline">\(f(y|X)\)</span> is called <strong>evidence</strong>. Finally, <span class="math inline">\(f(\beta|y,X)\)</span> is the <strong>posterior</strong> belief of pararmeter <span class="math inline">\(\beta\)</span> once the evidence <span class="math inline">\(y\)</span> has been taken into account. This posterior then becomes new prior and the circle continues recursively.</p>
<p>In this post we will bring the example from <a href="/classical-linear-regression.html" title="last post">last post</a> into Bayesian world.</p>
<p>If you have difficulty viewing the formulas, right click on it and select Math Settings Math Renderer to switch to another format.</p>
<a id="more"></a>
<h2 id="conjugate-bayesian-simple-regression">Conjugate Bayesian Simple Regression</h2>
<p>Let's continue to use the example from <a href="/classical-linear-regression.html" title="last post">last post</a> but re-phrase it in Bayesian way as follows</p>
<p><span class="math display">\[
y \sim N(X\beta, \sigma_eI) \\\\
\beta \sim N(\beta_0, \Sigma_{\beta,0})
\tag{2.1}
\]</span></p>
<p>where the second formula claims that the <strong>prior</strong> distribution of parameter <span class="math inline">\(\beta\)</span> is normal distribution with hyper-parameters <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\Sigma_{\beta,0}\)</span>; and the first formula says that the <strong>likelihood</strong> also follows a normal distribution. As you can see, the key step is to find the missing <strong>posterior</strong> distribution determined by Bayes Theorem.</p>
<p>To achieve this, we exploit a critical property known as <a href="https://en.wikipedia.org/wiki/Conjugate_prior" target="_blank" rel="noopener">conjugate prior</a> in the <a href="https://en.wikipedia.org/wiki/Normal-inverse-gamma_distribution" target="_blank" rel="noopener">Normal Inverse Gamma family</a>. It mathematically proves that a normally distributed <strong>prior</strong> conjugates with normally distributed <strong>likelihood</strong> to produce a normally distributed <strong>posterior</strong> as</p>
<p><span class="math display">\[
\beta \sim N(\beta_1, \Sigma_{\beta,1})
\tag{2.2}
\]</span></p>
<p>Now the question becomes to find new hyper-parameter <span class="math inline">\(\beta_1\)</span> and its standard deviation <span class="math inline">\(\Sigma_{\beta,1}\)</span>.</p>
<p>Specifically in our previous example of simple linear regression,</p>
<p><span class="math display">\[
y=X\beta+\epsilon=a+bx+\epsilon
\tag{2.3}
\]</span></p>
<p>where <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are intercept and slope, respectively. The hyper-parameters of prior are defined as</p>
<p><span class="math display">\[
 \begin{matrix}
\beta_0 &amp;=&amp; \begin{bmatrix} a_0 \\\\ b_0 \end{bmatrix} \\\\
\Sigma_{\beta,0} &amp;=&amp; \begin{bmatrix} \sigma_{a,0}^2 &amp; 0 \\\\ 0 &amp; \sigma_{b,0}^2 \end{bmatrix}
\end{matrix}
\tag{2.4}
 \]</span></p>
<p>if we observe two points <span class="math inline">\((x_1,y_1)\)</span> and <span class="math inline">\((x_2, y_2)\)</span> (it takes two points to determine a line), by using the <a href="https://en.wikipedia.org/wiki/Conjugate_prior" target="_blank" rel="noopener">Multivariate normal with known covariance matrix <span class="math inline">\(\Sigma\)</span></a> (in our case two-points means bi-variate), the posterior is given as</p>
<p><span class="math display">\[
\begin{matrix}
\beta_1 &amp;=&amp; \Sigma_{\beta,1}(\Sigma_{\beta,0}^{-1}\beta_0+\Sigma_y^{-1}\mu_y)\\\\
\Sigma_{\beta,1} &amp;=&amp; (\Sigma_{\beta,0}^{-1} + \Sigma_{y}^{-1})^{-1}\\\\
\mu_y &amp;=&amp; \begin{bmatrix} \frac{x_1y_2-x_2y_1}{x_1-x_2} &amp; \frac{y_1-y_2}{x_1-x_2} \end{bmatrix}^T    \\\\
\Sigma_{y} &amp;=&amp; \begin{bmatrix} [(\frac{x_1}{x_1-x_2})^2+(\frac{x_2}{x_1-x_2})^2]\sigma_e^2 &amp; 0 \\\\ 0 &amp; 2(\frac{1}{x_1-x_2})^2\sigma_e^2 \end{bmatrix}
\end{matrix}
\tag{2.5}
\]</span></p>
<p>After that, <span class="math inline">\(\beta_1\)</span>, <span class="math inline">\(\Sigma_{\beta,1}\)</span> become <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\Sigma_{\beta,0}\)</span> and the iteration continues.</p>
<p><strong>The formula seems complicated but conceptually it is very simple</strong>. Here is how it works. Imagine that in the beginning you believe the regression line should be horizontal. But then the first two points turn out to be vertical. So you think you might be wrong and you might not be so sure about things therefore you curved and tilt yourself toward the observed vertical line to somewhere 45 degrees. This is essentially what the above formulas do.</p>
<p>Then you continue to run another 249 time (because we have 500 points or 250 pairs). Everytime you adjust your previous belief by next two points you observe. It is easy to see that the longer you go, the less important it is where original starting belief is. Furthermore, there is nothing stopping you from reusing them again after you finish all the 500 points. It will make the estimation less and less dependent on the starting point and converges closer and closer to the true value.</p>
<p>As usual, here is the code implementation.</p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># don't forget to generate the 500 random samples as in the previous post</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># initial belief</span></span><br><span class="line">sigma_e = <span class="number">3.0</span>            <span class="comment"># make it known to avoid inverse gamma complexity</span></span><br><span class="line">a_0 = <span class="number">0.5</span></span><br><span class="line">b_0 = <span class="number">0.5</span></span><br><span class="line">sigma_a_0 = <span class="number">0.5</span></span><br><span class="line">sigma_b_0 = <span class="number">0.5</span></span><br><span class="line">beta_0 = np.array([[a_0], [b_0]])</span><br><span class="line">sigma_beta_0 = np.array([[sigma_a_0*sigma_a_0, <span class="number">0</span>], [<span class="number">0</span>, sigma_b_0*sigma_b_0]])</span><br><span class="line"></span><br><span class="line">beta_recorder = []           <span class="comment"># record parameter beta</span></span><br><span class="line">beta_recorder.append(beta_0)</span><br><span class="line"><span class="keyword">for</span> pair <span class="keyword">in</span> range(<span class="number">250</span>):       <span class="comment"># 500 points means 250 pairs</span></span><br><span class="line">    x1 = x[pair*<span class="number">2</span>]</span><br><span class="line">    x2 = x[pair*<span class="number">2</span>+<span class="number">1</span>]</span><br><span class="line">    y1 = y[pair*<span class="number">2</span>]</span><br><span class="line">    y2 = y[pair*<span class="number">2</span>+<span class="number">1</span>]</span><br><span class="line">    mu_y = np.array([[(x1*y2-x2*y1)/(x1-x2)], [(y1-y2)/(x1-x2)]])</span><br><span class="line">    sigma_y = np.array([[(np.square(x1/(x1-x2))+np.square(x2/(x1-x2)))*np.square(sigma_e),<span class="number">0</span>],</span><br><span class="line">                             [<span class="number">0</span>,<span class="number">2</span>*np.square(sigma_e/(x1-x2))]])</span><br><span class="line">    sigma_beta_1 = np.linalg.inv(np.linalg.inv(sigma_beta_0)+np.linalg.inv(sigma_y))</span><br><span class="line">    beta_1 = sigma_beta_1.dot(np.linalg.inv(sigma_beta_0).dot(beta_0) + np.linalg.inv(sigma_y).dot(mu_y))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># assign beta_1 to beta_0</span></span><br><span class="line">    beta_0 = beta_1</span><br><span class="line">    sigma_beta_0 = sigma_beta_1</span><br><span class="line">    beta_recorder.append(beta_0)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'pamameters: %.7f, %.7f'</span> %(beta_0[<span class="number">0</span>], beta_0[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># plot the Beyesian dynamics</span></span><br><span class="line">xfit = np.linspace(<span class="number">0</span>, <span class="number">10</span>, sample_size)</span><br><span class="line">ytrue = <span class="number">2.0</span> * xfit + <span class="number">1.0</span>       <span class="comment"># we know the true value of slope and intercept</span></span><br><span class="line">plt.plot(xfit, ytrue, label=<span class="string">'true line'</span>, linewidth=<span class="number">3</span>)</span><br><span class="line">y0 = beta_recorder[<span class="number">0</span>][<span class="number">1</span>] * xfit + beta_recorder[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">plt.plot(xfit, y0, label=<span class="string">'initial belief'</span>, linewidth=<span class="number">1</span>)</span><br><span class="line">y1 = beta_recorder[<span class="number">1</span>][<span class="number">1</span>] * xfit + beta_recorder[<span class="number">1</span>][<span class="number">0</span>]</span><br><span class="line">plt.plot(xfit, y1, label=<span class="string">'1st update'</span>, linewidth=<span class="number">1</span>)</span><br><span class="line">y10 = beta_recorder[<span class="number">10</span>][<span class="number">1</span>] * xfit + beta_recorder[<span class="number">10</span>][<span class="number">0</span>]</span><br><span class="line">plt.plot(xfit, y10, label=<span class="string">'10th update'</span>, linewidth=<span class="number">1</span>)</span><br><span class="line">y100 = beta_recorder[<span class="number">100</span>][<span class="number">1</span>] * xfit + beta_recorder[<span class="number">100</span>][<span class="number">0</span>]</span><br><span class="line">plt.plot(xfit, y100, label=<span class="string">'100th update'</span>, linewidth=<span class="number">1</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure> The intercept and slope parameter estimations are 0.6549224 and 2.0135760, pretty close to the results from <a href="/classical-linear-regression.html" title="last post">last post</a>. The following graph illustrates how Bayesian updates get to the true value from initial belief.</p>
<!--<img src="bayesian-linear-regression/bayesian_dynamics.png" align="left" width="100%" height="100%">-->
<img src="/bayesian-linear-regression/bayesian_dynamics.png" class="" title="Bayesian Dynamics">
<p>That's all about Bayesian Linear regression. Nowadays we can import packages such as PyMC3 to solve it numerically without knowing the closed form details. But I still think it is useful to grasp the concepts by a simple example. Thanks for reading.</p>
<p><strong>Reference</strong></p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Bayes%27_theorem" target="_blank" rel="noopener">Bayes Theorem, Wikipedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Conjugate_prior" target="_blank" rel="noopener">Conjugate Prior, Wikipedia</a></li>
</ul>
<p><strong>DISCLAIMER: This post is for the purpose of research and backtest only. The author doesn't promise any future profits and doesn't take responsibility for any trading losses.</strong></p>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>Post author:  </strong>Letian Wang
  </li>
  <li class="post-copyright-link">
    <strong>Post link: </strong>
    <a href="https://letianzj.github.io/bayesian-linear-regression.html" title="Bayesian Linear Regression">https://letianzj.github.io/bayesian-linear-regression.html</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> unless stating additionally.
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Machine-Learning/" rel="tag"># Machine Learning</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/classical-linear-regression.html" rel="prev" title="Classical Linear Regression">
      <i class="fa fa-chevron-left"></i> Classical Linear Regression
    </a></div>
      <div class="post-nav-item">
    <a href="/mcmc-linear-regression.html" rel="next" title="MCMC Linear Regression">
      MCMC Linear Regression <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  <div class="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#conjugate-bayesian-simple-regression"><span class="nav-number">2.</span> <span class="nav-text">Conjugate Bayesian Simple Regression</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Letian Wang"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">Letian Wang</p>
  <div class="site-description" itemprop="description">Letian Wang blog to discuss quantitative trading strategies, portfolio management, risk premia, risk management, systematic trading, and machine learning, deep learning applications in Finance.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">19</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">categories</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/letianzj" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;letianzj" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:letian.zj@gmail.com" title="E-Mail → mailto:letian.zj@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.linkedin.com/in/letian-wang-phd-cfa-frm-75b53312/" title="Linkedin → https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;letian-wang-phd-cfa-frm-75b53312&#x2F;" rel="noopener" target="_blank"><i class="fab fa-linkedin fa-fw"></i>Linkedin</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Letian Wang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://https-letianzj-github-io.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  var disqus_config = function() {
    this.page.url = "https://letianzj.github.io/bayesian-linear-regression.html";
    this.page.identifier = "bayesian-linear-regression.html";
    this.page.title = "Bayesian Linear Regression";
    };
  NexT.utils.loadComments(document.querySelector('#disqus_thread'), () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://https-letianzj-github-io.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });
</script>

</body>
</html>
